---
title: "ds2_homework1"
author: "Minghe Wang"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
library(glmnet)
library(caret)
library(tidymodels)
library(corrplot)
library(ggplot2)
library(plotmo)
library(ggrepel)
```

We predict the sale price of a house based on various characteristics. The training data are in `housing train.csv`, and the test data are in `housing test.csv`. The response is in the column “Sale price”, and other variables can be used as predictors. The variable definitions can be found in `dictionary.txt`.

```{r load_data}
house_train <- read_csv("./data/housing_training.csv")
house_test <- read_csv("./data/housing_test.csv")
house_train <- na.omit(house_train) %>% 
  mutate(across(where(is.character), as.factor))

house_test <- na.omit(house_test) %>% 
  mutate(across(where(is.character), as.factor))
# str(house_train)
# str(house_test)
```

## (a)

```{r 1a}
# cross validation setup
x <- model.matrix(Sale_Price ~ . -1, house_train)
y <- house_train$Sale_Price

set.seed(2025)
# cv.lasso <- cv.glmnet(x, y, 
#                       alpha = 1)
# print(max(cv.lasso$lambda)) # 54596.94
# print(min(cv.lasso$lambda)) # 38.51706

cv.lasso <- cv.glmnet(x, y, 
                      alpha = 1,
                      lambda = exp(seq(9, 3, length = 100)))

predict(cv.lasso, s = cv.lasso$lambda.min, type = "coefficients")

X_test <- model.matrix(Sale_Price ~ . - 1, data = house_test)
y_test <- house_test$Sale_Price

# Get predictions using the best lambda
predictions_min <- predict(cv.lasso, newx = X_test, s = cv.lasso$lambda.min)

# Calculate Mean Squared Error (MSE)
test_rmse_min <- sqrt(mean((predictions_min - y_test)^2))
```


Note: We predefined a range for tuning parameter based on the maximum and minimum lambda of the model with default(data-driven) tuning parameter.

The selected tuning parameter $\lambda$ is `r cv.lasso$lambda.min`, and the test error(RMSE) is `r test_rmse_min`.

```{r 1a 1se rule lasso}
# get prediction w/ lambda + 1se
predictions_1se <- predict(cv.lasso, newx = X_test, s = cv.lasso$lambda.1se)

# get number of predictors
coef_1se_lasso <- predict(cv.lasso, s = cv.lasso$lambda.1se, type = "coefficients")
num_predictors_1se_lasso <- sum(coef_1se_lasso[-1] != 0) 

# Calculate Mean Squared Error (MSE)
test_rmse_1se <- sqrt(mean((predictions_1se - y_test)^2))
```

When applied 1SE rule(i.e. minimum lambda + 1 standard error), the model has number of predictors = `r num_predictors_1se_lasso` ; test error(RMSE) = `r test_rmse_1se`, which is acceptable.

## (b)

```{r 1b}
ctrl1 <- trainControl(method = "cv", number = 10, selectionFunction = "best")
ctrl2 <- trainControl(method = "cv", number = 10, selectionFunction = "oneSE")

set.seed(2025)

enet.fit_caret_bestPar <- train(Sale_Price ~ ., data = house_train,
                           method = "glmnet",
                           tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                                  lambda = exp(seq(9, 3, length = 100))),
                           trControl = ctrl1)



enet.fit_caret_1sePar <- train(Sale_Price ~ ., data = house_train,
                           method = "glmnet",
                           tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                                  lambda = exp(seq(9, 3, length = 100))),
                           trControl = ctrl2)

# cat("best lambda by caret:", enet.fit_glm$lambda.min) # 469.4281
# cat("1se lambda by caret:", enet.fit_caret$bestTune$lambda) # 529.9206

enet_pred_best <- predict(enet.fit_caret_bestPar, newdata = house_test, 
                          s = enet.fit_caret_bestPar$bestTune)
enet_pred_1se <- predict(enet.fit_caret_1sePar, newdata = house_test, 
                         s = enet.fit_caret_1sePar$bestTune)

test_rmse_enet_min <- sqrt(mean((y_test - enet_pred_best)^2))
test_rmse_enet_1se <- sqrt(mean((y_test - enet_pred_1se)^2))
```

The selected tuning parameter are $\lambda$ = `r enet.fit_caret_bestPar$bestTune$lambda`, $\alpha$ =  `r enet.fit_caret_bestPar$bestTune$alpha`, and its RMSE is `r test_rmse_enet_min`. 

1SE Rule can be applied to $\lambda$ only, not to $\alpha$. We need to use `caret` elastic net model to find the best tune $\alpha$ and then use `glmnet` to apply the 1SE Rule while keeping $\alpha$ fixed.

When 1SE Rule applied, the tuning parameters are $\alpha$ =  `r enet.fit_caret_1sePar$bestTune$alpha`, $\lambda$ = `r enet.fit_caret_1sePar$bestTune$lambda`, and test RMSE is `r test_rmse_enet_1se`. This result suggests that cross validation process might find the most optimal model is ridge regression for given dataset, which deserves further investigation on the reason behind it.

## (c)

```{r 1c}
set.seed(2025)
pls.fit_caret <- train(Sale_Price ~ ., data = house_train,
                   method = "pls",
                   tuneGrid = data.frame(ncomp = 1:29), 
                   trControl = ctrl1,
                   preProcess = c("center", "scale"))


best_ncomp_caret_pls <- pls.fit_caret$bestTune$ncomp 

pred_pls <- predict(pls.fit_caret, newdata = house_test)
test_rmse_pls <- sqrt(mean((y_test - pred_pls)^2))
```
The test RMSE using PLS model is `r test_rmse_pls`, and there are `r best_ncomp_caret_pls` components selected by the best PLS model.

## (d)

```{r 1d}
error_table <- data.frame(
  Model = c("LASSO", "Elastic Net", "PLS"),
  Test_RMSE = c(test_rmse_min, test_rmse_enet_min, test_rmse_pls)
) 

print(error_table)
```


## (e)

```{r 1e}
set.seed(2025)
lasso.fit_caret <- train(Sale_Price ~ ., data = house_train,
                         method = "glmnet",
                         tuneGrid = expand.grid(alpha = 1,
                                                lambda = exp(seq(9, 3, length = 100))),
                         trControl = ctrl1)


lambda_glm <- cv.lasso$lambda.min
lambda_caret <- lasso.fit_caret$bestTune$lambda
plot(cv.lasso)
plot(lasso.fit_caret, xTrans = log)
```

By `glmnet`, the tuning parameter $\lambda$ = `r lambda_glm`; by `caret`, $\lambda$ = `r lambda_caret`. Even though we specify using `glmnet` method in `caret` model fitting, there is still difference in selection of "best" $\lambda$. However, we consider this as an acceptable difference especially when considering within the exponential grid($log(\lambda_{glm})$ = `r log(lambda_glm)`; $log(\lambda_{caret})$ = `r log(lambda_caret)`). The source of such difference might be from how each function sets up cross-validation or potentially different default error metrics or tie-breaking decisions.

```{r caret models compare}
set.seed(2025)
resamp <- resamples(list(
  Lasso = lasso.fit_caret,
  ElasticNet = enet.fit_caret_bestPar,
  PartialLeastSq = pls.fit_caret
))

summary(resamp)
```

In last question, we found the Elastic Net slightly outperform the other two model by measuring RMSE. Since we just fit the lasso model w/ `caret`, we can directly compare how well three model predicts on test data. And the result aligns w/ our belief that Elastic Net still perform better than other two models overall.

```{r caret model adjustment}
set.seed(2025)
train_id_list <- lasso.fit_caret$control$index

dat_dummy <- data.frame(Sale_Price = y, x)
M <- 10
lambda.grid <- exp(seq(9, 3, length = 100))
rmse <- rmse_caret <- matrix(NA, ncol = 100, nrow = M)

for (m in 1:M)
{
  tsdata <- dat_dummy[train_id_list[[m]],] 
  vsdata <- dat_dummy[-train_id_list[[m]],] 
  
  x1 <- as.matrix(tsdata[,-1])
  y1 <- tsdata[,1]
  x2 <- as.matrix(vsdata[,-1])
  y2 <- vsdata[,1]
  
  fit <- glmnet(x1, y1, alpha = 1, 
                lambda = lambda.grid)
  
  # caret implementation did not specify lambda
  # the default grid of lambda is different from lambda.grid
  fit_caret <- glmnet(x1, y1, alpha = 1)
  
  pred <- predict(fit, newx = x2, s = lambda.grid)
  pred_caret <- predict(fit_caret, newx = x2, s = lambda.grid)
  
  rmse[m,] <- sqrt(colMeans((y2 - pred)^2))
  rmse_caret[m,] <- sqrt(colMeans((y2 - pred_caret)^2))
}

# curve from glmnet (correct)
plot(log(lambda.grid), colMeans(rmse), col = 3, xlab = "log(lambda)", ylab = "CV RMSE")
abline(v = log(lambda.grid[which.min(colMeans(rmse))]))

# caret results
points(log(lasso.fit_caret$results$lambda), lasso.fit_caret$results$RMSE, col = 2)

# try to reproduce caret results from scratch
points(log(lambda.grid), colMeans(rmse_caret), col = rgb(0,0,1,alpha = 0.3))


# selected lambda
lambda.grid[which.min(colMeans(rmse))]

# the corresponding CV RMSE
min(colMeans(rmse))
```

As being awared of an small implementation error of caret model, we adjust the algorithm of caret. And the selection of lambda is still in an acceptable range comparing to glmnet.